# Speech-Emotion-Recognition-SER-
MFCCs for SER, dataset is created to predict emotions based on the values. The values are extracted from audios taken from RAVDESS, CREMA-D, TESS, and SAVEE. 
This dataset includes 24 actors, each vocalizing two statements in a neutral North American accent. The dataset includes eight different emotions, including sad, angry, neutral, happy, surprised, disgust, calm, and fearful.
Mel Frequency Cepstral Coefficient (MFCC) technique is used to recognize emotion of a speaker from their voice. The designed system was validated for Happy, sad and anger emotions and the efficiency was found to be about 80%.
Dataset created with the aim to predict females and males emotions based on MFCCs values. With this setup (58 values for each emotion) we were been able to get a good 94% accuracy on the female emotions.
